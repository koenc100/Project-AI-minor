{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1080780",
   "metadata": {},
   "source": [
    "# Combined model\n",
    "\n",
    "In this notebook we will combine the optimized version of the three models we've created. So, the predictions of our k-Nearest Neighbor, Decision tree and Neural Network will be combined to one new prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0adf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instal nbimporter to be able to import functions from other notebooks\n",
    "pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e095329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import prepare_data, split_data, one_hot_encode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nbimporter\n",
    "from helper_functions import get_metrics\n",
    "\n",
    "# Import functions for k-nearest neighbors\n",
    "from kNN_die_wel_opent import split_datatypes, train_and_predict\n",
    "from oversampling import smote_loop\n",
    "\n",
    "# Import functions for decision tree\n",
    "from Decision_tree import resampled_forest\n",
    "\n",
    "# Import functions for deep neural networks\n",
    "from deep_neural_network import train_and_predict as train_dNN\n",
    "from deep_neural_network import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1baadbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data normalized\n",
    "data = prepare_data('healthcare-dataset-stroke-data.csv', one_hot = False, binary = False, normalize = True)\n",
    "\n",
    "# Split the normalized data into training, testing and validation data\n",
    "train_data, test_data, val_data, train_labels, test_labels, val_labels = split_data(data, (0.6, 0.2, 0.2))\n",
    "\n",
    "# Change the data to one-hot encoded data\n",
    "train_hot = one_hot_encode(train_data)\n",
    "test_hot = one_hot_encode(test_data)\n",
    "val_hot = one_hot_encode(val_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a614303",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbor\n",
    "The k-Nearest Neighbor model with the best balanced accuracy was trained on only numeric data that was overfitted with a ratio of 0.6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84a21ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Split test data into numeric and binary data\n",
    "test_num, test_bin = split_datatypes(test_hot)\n",
    "val_num, val_bin = split_datatypes(val_hot)\n",
    "\n",
    "# Get the oversampled data with a oversampling ratio of 0.6\n",
    "data_list, labels_list, ratio_list = smote_loop(train_data, train_labels, 0.6, 0.7, 0.1)\n",
    "train_num, train_bin = split_datatypes(data_list[0])\n",
    "\n",
    "# Predictions using model trained on numerical, oversampled data and euclidean distance metric and 5 neighbors\n",
    "predict_train_kNN, predict_val_kNN = train_and_predict(train_num, labels_list[0], val_num, 5, \"distance\", \n",
    "                                                          metric='euclidean')\n",
    "predict_train_kNN, predict_test_kNN = train_and_predict(train_num, labels_list[0], test_num, 5, \"distance\", \n",
    "                                                          metric='euclidean')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64cbf83",
   "metadata": {},
   "source": [
    "### Resampled Forest\n",
    "The optimal number of splits was around 17 most of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38cbdbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tuple of the data that gets accepted by the forest function\n",
    "data_DT_val = (train_hot, train_labels, val_hot, val_labels)\n",
    "data_DT_test = (train_hot, train_labels, test_hot, test_labels)\n",
    "\n",
    "# Train the forest on the training data and return a list with predicted labels fror training and testing data\n",
    "predict_train_DT, predict_val_DT = resampled_forest(data_DT_val, 17)\n",
    "predict_train_DT, predict_val_DT = resampled_forest(data_DT_val, 17)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdb1414",
   "metadata": {},
   "source": [
    "### Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3cc9b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Deep Neural Network with two hidden layers \n",
    "model = get_model(train_hot, hidden_layers=2, nodes=[25, 15], dropout_rate=[0.3, 0.3])\n",
    "\n",
    "# Get the predictions for the training and testing data using the Deep Neural Network\n",
    "predictions_train, predictions_test, history = train_dNN(model, train_hot, train_labels, test_hot, test_labels, \n",
    "                                                         class_weight = 15, plot=False, batch_size=None, epochs=50, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd24514",
   "metadata": {},
   "source": [
    "# Combining the models\n",
    "The models can be combined in different ways. Considering we started with too few stroke predictions an OR function might be good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5beb15ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy using only k-Nearest Neighbors: \n",
      "accuracy: 83.2681 % \n",
      "\n",
      "balanced accuracy: 68.4383 %\n",
      "sensitivity: 0.5200\n",
      "specificity: 0.8488 \n",
      "\n",
      "confusion matrix: \n",
      "[[825 147]\n",
      " [ 24  26]] \n",
      "\n",
      "[[\"True Negative\", \"False Positive\"] \n",
      " [\"False Negative\", \"True Positive\"]] \n",
      "\n",
      "The accuracy using only Resampled Forest: \n",
      "accuracy: 74.4618 % \n",
      "\n",
      "balanced accuracy: 76.1399 %\n",
      "sensitivity: 0.7800\n",
      "specificity: 0.7428 \n",
      "\n",
      "confusion matrix: \n",
      "[[722 250]\n",
      " [ 11  39]] \n",
      "\n",
      "[[\"True Negative\", \"False Positive\"] \n",
      " [\"False Negative\", \"True Positive\"]] \n",
      "\n",
      "The accuracy using the deep Neural Netwerk: \n",
      "accuracy: 74.9511 % \n",
      "\n",
      "balanced accuracy: 74.5000 %\n",
      "sensitivity: 0.7400\n",
      "specificity: 0.7500 \n",
      "\n",
      "confusion matrix: \n",
      "[[729 243]\n",
      " [ 13  37]] \n",
      "\n",
      "[[\"True Negative\", \"False Positive\"] \n",
      " [\"False Negative\", \"True Positive\"]] \n",
      "\n",
      "The accuracy using the combined predictions: \n",
      "accuracy: 77.1037 % \n",
      "\n",
      "balanced accuracy: 73.7346 %\n",
      "sensitivity: 0.7000\n",
      "specificity: 0.7747 \n",
      "\n",
      "confusion matrix: \n",
      "[[753 219]\n",
      " [ 15  35]] \n",
      "\n",
      "[[\"True Negative\", \"False Positive\"] \n",
      " [\"False Negative\", \"True Positive\"]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_test = predictions_test.reshape(1022, )\n",
    "predict_combined_test = (predict_test_kNN + predict_test_DT + predictions_test) >= 2\n",
    "\n",
    "print('The accuracy using only k-Nearest Neighbors: ')\n",
    "test_acc, test_balacc = get_metrics(test_labels, predict_test_kNN, verbose = True)\n",
    "print('The accuracy using only Resampled Forest: ')\n",
    "test_acc, test_balacc = get_metrics(test_labels, predict_test_DT, verbose = True)\n",
    "print('The accuracy using the deep Neural Netwerk: ')\n",
    "test_acc, test_balacc = get_metrics(test_labels, predictions_test, verbose = True)\n",
    "\n",
    "print('The accuracy using the combined predictions: ')\n",
    "test_acc, test_balacc = get_metrics(test_labels, predict_combined_test, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2656b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      knn     DT     NN\n",
      "0       0  False  False\n",
      "1       0  False  False\n",
      "2       0  False  False\n",
      "3       0  False  False\n",
      "4       0  False  False\n",
      "...   ...    ...    ...\n",
      "1017    0  False  False\n",
      "1018    0  False  False\n",
      "1019    1   True   True\n",
      "1020    1  False  False\n",
      "1021    0  False  False\n",
      "\n",
      "[1022 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "combined_test = pd.DataFrame({'knn': predict_test_kNN, 'DT': predict_test_DT, 'NN': predictions_test})\n",
    "\n",
    "model = get_model(combined, hidden_layers=2, nodes=[25, 15], dropout_rate=[0.3, 0.3])\n",
    "\n",
    "predictions_train, predictions_test, history = train_dNN(model, combined, test_labels, val_hot, val_labels,\n",
    "                                                        class_weight = 10, plot=True, batch_size=None,\n",
    "                                                        epochs=50, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
