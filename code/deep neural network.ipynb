{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Analysis\n",
    "\n",
    "This section should describe what the actual input is your model starts with, and what type of model is used, including the structure of the model itself (i.e. what layers of what shape, and with which activation function are used in your neural network), and what post-processing steps do you do before making the actual prediction.\n",
    "\n",
    "In this project we try to predict whether people will have a stroke or not.  \n",
    "\n",
    "#### Data Pipeline\n",
    "\n",
    "#### Model Training\n",
    "\n",
    "#### Model evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from data_processing import prepare_data, split_data\n",
    "from helper_functions import get_metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, preprocessing, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data('healthcare-dataset-stroke-data.csv')\n",
    "# Split the data\n",
    "train_data, test_data, val_data, train_labels, test_labels, val_labels = split_data(data, split_size=(0.6, 0.2, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2945 samples\n",
      "Epoch 1/5\n",
      "2945/2945 [==============================] - 0s 107us/sample - loss: 0.2414 - accuracy: 0.9535\n",
      "Epoch 2/5\n",
      "2945/2945 [==============================] - 0s 25us/sample - loss: 0.1832 - accuracy: 0.9559\n",
      "Epoch 3/5\n",
      "2945/2945 [==============================] - 0s 24us/sample - loss: 0.1776 - accuracy: 0.9552\n",
      "Epoch 4/5\n",
      "2945/2945 [==============================] - 0s 25us/sample - loss: 0.1781 - accuracy: 0.9548\n",
      "Epoch 5/5\n",
      "2945/2945 [==============================] - 0s 26us/sample - loss: 0.1718 - accuracy: 0.9521\n",
      "train metrics: \n",
      "\n",
      "accuracy: 95.9593 % \n",
      "\n",
      "balanced accuracy: 50.0000 % \n",
      "\n",
      "confusion matrix: \n",
      "[[2826    0]\n",
      " [ 119    0]] \n",
      "\n",
      "[[\"True Negative\", \"False Positive\"] \n",
      " [\"False Negative\", \"True Positive\"]] \n",
      "\n",
      "test metrics: \n",
      "\n",
      "accuracy: 94.8065 % \n",
      "\n",
      "balanced accuracy: 50.0000 % \n",
      "\n",
      "confusion matrix: \n",
      "[[931   0]\n",
      " [ 51   0]] \n",
      "\n",
      "[[\"True Negative\", \"False Positive\"] \n",
      " [\"False Negative\", \"True Positive\"]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_and_predict(model, training_data, training_labels, testing_data, testing_labels, epochs=5):\n",
    "    # fit model\n",
    "    model.fit(training_data, training_labels, epochs=epochs)\n",
    "    \n",
    "\n",
    "    # predict training data\n",
    "    predictions_train = model.predict(training_data)\n",
    "    predictions_train = np.argmax(predictions_train, axis=1)\n",
    "    \n",
    "    # predict testing data\n",
    "    predictions_test = model.predict(testing_data)\n",
    "    predictions_test = np.argmax(predictions_test, axis=1)\n",
    "\n",
    "    return predictions_train, predictions_test\n",
    "\n",
    "\n",
    "# create model\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(Input(shape=(21,)))\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "model.add(layers.Dense(2, 'softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train and predict\n",
    "predictions_train, predictions_test = train_and_predict(model, train_data, \n",
    "                                                        train_labels, test_data, \n",
    "                                                        test_labels, epochs=5)\n",
    "\n",
    "# Print metrics\n",
    "print('train metrics: \\n')\n",
    "accuracy_train, balanced_accuracy_train = get_metrics(train_labels, predictions_train, verbose=True)\n",
    "\n",
    "print('test metrics: \\n')\n",
    "accuracy_test, balanced_accuracy_test = get_metrics(test_labels, predictions_test, verbose=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
