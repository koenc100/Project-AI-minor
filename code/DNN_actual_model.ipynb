{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import statistics\n",
    "from oversampling import one_hot, smote_loop\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "from data_processing import prepare_data, split_data\n",
    "from helper_functions import get_metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, preprocessing, Input, metrics, initializers\n",
    "from tensorflow.keras.metrics import FalsePositives, TruePositives, FalseNegatives, TrueNegatives\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data and clean it\n",
    "data = prepare_data('healthcare-dataset-stroke-data.csv')\n",
    "#data.replace({0: -1})\n",
    "# Split the data into test, training and validation data\n",
    "train_data, test_data, val_data, train_labels, test_labels, val_labels = split_data(data, split_size=(0.6, 0.2, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-thailand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual model\n",
    "\n",
    "def train_and_predict(model, training_data, training_labels, \n",
    "                      testing_data, testing_labels, epochs=5, \n",
    "                      class_weight=10, verbose=0, plot=True):\n",
    "    \"\"\"\n",
    "    This function trains a given neural network model based on training data and training labels. It then predicts classes on\n",
    "    training and testing data. \n",
    "    It is possible to adjust for how many epochs the model is trained and how to weight the sparse class.\n",
    "    \n",
    "    input:\n",
    "    \n",
    "    model:        model architecture defined before calling this function\n",
    "    class_weight:  errors on the stroke class should be weighted heavier then the non-stroke class. \n",
    "                  The value defines how much more this loss is weighted. loss_weight=10 means a ratio of 1 to 10.\n",
    "                  For some reason\n",
    "    verbose:      0: no text per epoch\n",
    "                  1: text for each epoch\n",
    "    plot:         True: show accuracy and loss over epochs in figure\n",
    "                  False: no plot\n",
    "                  \n",
    "    output: \n",
    "    \n",
    "    predictions_train: vector of training predictions\n",
    "    predictions_test:  vector of test predictions\n",
    "    history:           dict containing measures over epochs, including loss, accuracy, TP, FP, TN, FN, for train and test data.\n",
    "                       print history.history for all measures and their keys.\n",
    "    \n",
    "    \"\"\"\n",
    "   \n",
    "    # Compile the layers of the model defined earlier. Use the binary cross entropy function as the loss function as we only\n",
    "    # have 2 output classes and use accuracy as the metric\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # set warnings off (annoying bug in tensorflow)\n",
    "    tf.get_logger().setLevel('ERROR')\n",
    "    # Train the model for a number of epochs\n",
    "    history = model.fit(training_data, training_labels, epochs=epochs, \n",
    "                        validation_data=(testing_data, testing_labels),\n",
    "                        class_weight=[{0: 1., 1: class_weight}],\n",
    "                        #sample_weight=[None],\n",
    "                        verbose=verbose\n",
    "                       )\n",
    "    # set warnings on again \n",
    "    tf.get_logger().setLevel('INFO')\n",
    "\n",
    "    # Predict the classes of the training data\n",
    "    predictions_train = model.predict(training_data) >= 0.5\n",
    "    \n",
    "    # Predict the classes on the testing data\n",
    "    predictions_test = model.predict(testing_data) >= 0.5\n",
    "    \n",
    "    # Plot the loss and accuracy over epochs.\n",
    "    if plot:\n",
    "        fig, axs = plt.subplots(1, 2)\n",
    "        fig.suptitle('loss and accuracy')\n",
    "    \n",
    "        axs[0].plot(history.history['accuracy'])\n",
    "        axs[0].plot(history.history['val_accuracy'])\n",
    "        axs[0].legend(['train', 'test'], loc='upper left')\n",
    "        axs[0].set_title('accuracy')\n",
    "        axs[0].set_ylabel('accuracy')\n",
    "        axs[0].set_xlabel('epochs')\n",
    "\n",
    "\n",
    "        # Plot the loss over epochs\n",
    "        axs[1].plot(history.history['loss'])\n",
    "        axs[1].plot(history.history['val_loss'])\n",
    "        axs[1].set_title('loss')\n",
    "        axs[1].set_xlabel('epochs')\n",
    "        axs[1].set_ylabel('loss')\n",
    "        axs[1].legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    return predictions_train, predictions_test, history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    # Get the amount of input features for the nodes in the first layer\n",
    "    input_shape = np.shape(train_data)[1]\n",
    "\n",
    "    # Create the model\n",
    "    initializer = initializers.RandomNormal(mean=0.0, stddev=0.05, seed=12345)\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # First layer with input nodes equal to features\n",
    "    model.add(Input(shape=(input_shape)))\n",
    "\n",
    "    # One hidden layer with 25 nodes\n",
    "    model.add(layers.Dense(25, activation='relu', kernel_initializer=initializer))\n",
    "\n",
    "    model.add(layers.Dense(10, activation='relu', kernel_initializer=initializer))\n",
    "\n",
    "    # Output layer with 1 node (only 1 output class, 0 or 1 for stroke) and sigmoid activation function\n",
    "    model.add(layers.Dense(1, 'sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "# Train and predict\n",
    "predictions_train, predictions_test, history = train_and_predict(model, train_data, \n",
    "                                                        train_labels, test_data, test_labels,\n",
    "                                                        class_weight = 10,\n",
    "                                                        epochs=30, verbose=0)\n",
    "\n",
    "# Print metrics\n",
    "print('train metrics: \\n')\n",
    "accuracy_train, balanced_accuracy_train = get_metrics(train_labels, predictions_train, verbose=True)\n",
    "\n",
    "print('test metrics: \\n')\n",
    "accuracy_test, balanced_accuracy_test = get_metrics(test_labels, predictions_test, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different class weights and plot accuracy and sensitivity\n",
    "\n",
    "accuracies_val = []\n",
    "sensitivities_val = []\n",
    "balanced_accuracies_val = []\n",
    "specificities_val = []\n",
    "\n",
    "for i in tqdm(range(1, 30, 2)):\n",
    "    \n",
    "    # Train and predict\n",
    "    predictions_train, predictions_val, history = train_and_predict(model, train_data, \n",
    "                                                          train_labels, val_data, val_labels,\n",
    "                                                          epochs=30, verbose=0, plot=False,\n",
    "                                                          class_weight=i)\n",
    "    \n",
    "    # metrics\n",
    "    accuracy_val, balanced_accuracy_val = get_metrics(val_labels, predictions_val, verbose=False)\n",
    "    conmat = confusion_matrix(test_labels, predictions_val)\n",
    "    sensitivity = conmat[1,1] / sum(conmat[1,:])\n",
    "    specificity = conmat[0,0] / sum(conmat[0,:])\n",
    "\n",
    "    accuracies_val.append(accuracy_val)\n",
    "    balanced_accuracies_val.append(balanced_accuracy_val)\n",
    "    sensitivities_val.append(sensitivity)\n",
    "    specificities_val.append(specificity)\n",
    "    \n",
    "## Plot metrics over  class weights.\n",
    "\n",
    "plt.plot(range(1,30,2), accuracies_val)\n",
    "plt.plot(range(1,30,2), balanced_accuracies_val)\n",
    "plt.plot(range(1,30,2), sensitivities_val)\n",
    "plt.plot(range(1,30,2), specificities_val)\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Effect of class weights on different output metrics in validation data')\n",
    "plt.ylabel('proportions')\n",
    "plt.xlabel('Relative weight of stroke class')\n",
    "plt.legend(['accuracy', 'balanced_accuracy', 'sensitivity', 'specificity'])\n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data and clean it\n",
    "data = prepare_data('healthcare-dataset-stroke-data.csv', one_hot = False, binary = True, normalize = True)\n",
    "\n",
    "#data.replace({0: -1})\n",
    "# Split the data into test, training and validation data\n",
    "train_data, test_data, val_data, train_labels, test_labels, val_labels = split_data(data, split_size=(0.6, 0.2, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tryout with different oversampling ratios\n",
    "\n",
    "oversampling_val = []\n",
    "oversampling_val_bal = []\n",
    "\n",
    "# Define categorial features\n",
    "n_features = np.array([True, False, True, True, True, True,True, False, False, True])\n",
    "\n",
    "print(train_data)\n",
    "\n",
    "list_data, list_labels, list_ratio = smote_loop(train_data, train_labels, n_features, 0.2, 1.01, 0.2)\n",
    "\n",
    "for data_res, labels_res in zip(list_data, list_labels):\n",
    "    \n",
    "    # Train and predict\n",
    "    predictions_train, predictions_val, history = train_and_predict(model, data_res, \n",
    "                                                          labels_res, val_data, val_labels,\n",
    "                                                          epochs=30, verbose=0, plot=False,\n",
    "                                                          class_weight=[{0: 1., 1: 10}])\n",
    "    \n",
    "    # metrics\n",
    "    accuracy_val, balanced_accuracy_val = get_metrics(val_labels, predictions_val, verbose=False)\n",
    "\n",
    "    oversampling_val.append(accuracy_val)\n",
    "    oversampling_val_bal.append(balanced_accuracy_val)\n",
    "    \n",
    "## Plot metrics over  class weights.\n",
    "\n",
    "plt.plot(np.linspace(0.2, 1, 5), accuracies_val)\n",
    "plt.plot(np.linspace(0.2, 1, 5), balanced_accuracies_val)\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Effect of class weights on different output metrics in validation data')\n",
    "plt.ylabel('proportions')\n",
    "plt.xlabel('Relative weight of stroke class')\n",
    "plt.legend(['accuracy', 'balanced_accuracy'])\n",
    "plt.show()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-software",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
